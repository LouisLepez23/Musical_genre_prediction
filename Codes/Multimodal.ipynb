{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFXv28p45sn1",
        "outputId": "873ac11b-4ad3-4120-dd35-9712d1e9eca7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zm6iM4Jn58EA"
      },
      "outputs": [],
      "source": [
        "Directive_louis = '/content/drive/MyDrive/Centrale Marseille/3A/SAM/Projet/'\n",
        "Directive_guillaume ='/content/drive/MyDrive/Centrale Marseille/3A/SAM/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P84O93eC6Vvy",
        "outputId": "a153370a-c927-4698-8f02-64355403e0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/214.3 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m204.8/214.3 KB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 KB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgNxEztU6ZgN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
        "import sys\n",
        "sys.path.append(Directive_louis)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "A97HDakFqH7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiBm_3SM6fs4"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(Directive_guillaume + 'msdi.zip' , 'r') as zip:\n",
        "    zip.extractall('msdi')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = pd.read_csv('msdi/msdi_mapping.csv')\n",
        "mapping = mapping.sample(frac=1)"
      ],
      "metadata": {
        "id": "235JNOUyqEUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmi4v3NO6uJ_",
        "outputId": "2fce8e2a-ef3c-4cdd-d171-40f912e72194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deep_features  img  labels.csv\tmfcc  msdi_mapping.csv\tREADME.md\n"
          ]
        }
      ],
      "source": [
        "!ls msdi/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu_3rPYH7YUd",
        "outputId": "211d127c-cceb-4afc-e3b4-6e778ccc1fc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ",msd_track_id,genre,album_index,set,msd_artist_id,image_url,img,mfcc,deep_features\n",
            "0,TRABKJU128F422A7FE,Metal,0,train,ARBD4QW1187FB42153,http://artwork-cdn.7static.com/static/img/sleeveart/00/008/487/0000848744_200.jpg,img/0000848744_200.jpg,mfcc/mfcc_A.npz,0\n",
            "1,TRBLDQQ128F92E58B4,Rock,1,train,AR3RK011187FB3CE3B,http://artwork-cdn.7static.com/static/img/sleeveart/00/004/765/0000476534_200.jpg,img/0000476534_200.jpg,mfcc/mfcc_B.npz,1\n",
            "2,TRDMMDE128F14A9052,Rock,2,train,ARJVTRE1187B9959C0,http://artwork-cdn.7static.com/static/img/sleeveart/00/000/623/0000062345_200.jpg,img/0000062345_200.jpg,mfcc/mfcc_D.npz,2\n",
            "3,TRJOPZB128F4250E02,Rock,4,train,AR62BB21187B9AC83D,http://artwork-cdn.7static.com/static/img/sleeveart/00/001/447/0000144785_200.jpg,img/0000144785_200.jpg,mfcc/mfcc_J.npz,3\n",
            "4,TRJKBVL128F935567B,Rock,5,train,AR7GVOV1187B9B5FF1,http://artwork-cdn.7static.com/static/img/sleeveart/00/005/205/0000520513_200.jpg,img/0000520513_200.jpg,mfcc/mfcc_J.npz,4\n",
            "5,TRUSOQD128F92CFEA5,Rock,7,train,ARZHQDD1187FB5B871,http://artwork-cdn.7static.com/static/img/sleeveart/00/003/188/0000318842_200.jpg,img/0000318842_200.jpg,mfcc/mfcc_U.npz,5\n",
            "6,TRKCEWE128F425BF56,Rock,9,train,ARRSEGJ1187B9A67D9,http://artwork-cdn.7static.com/static/img/sleeveart/00/002/780/0000278069_200.jpg,img/0000278069_200.jpg,mfcc/mfcc_K.npz,6\n",
            "7,TRRCUNU128F932C084,Reggae,10,train,ARDI8UK1187FB369FB,http://artwork-cdn.7static.com/static/img/sleeveart/00/003/642/0000364214_200.jpg,img/0000364214_200.jpg,mfcc/mfcc_R.npz,7\n",
            "8,TRRNTLC128F93366F6,Rock,11,train,ARTNHBW1187B9A5482,http://artwork-cdn.7static.com/static/img/sleeveart/00/005/495/0000549518_200.jpg,img/0000549518_200.jpg,mfcc/mfcc_R.npz,8\n"
          ]
        }
      ],
      "source": [
        "!head msdi/msdi_mapping.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "Ce projet a pour objectif de développer des algorithmes multimodaux pour la prédiction du genre musical d'une chanson en utilisant des informations visuelles, auditives et textuelles. Pour ce faire, nous allons implémenter des algorithmes de fusion tardive et précoce afin de combiner les informations provenant de différentes sources pour obtenir des résultats plus précis. Nous allons également comparer les performances de ces algorithmes multimodaux aux algorithmes unimodaux déjà implémentés dans une partie précédente pour les images et les extraits audio. En utilisant ces algorithmes, nous espérons obtenir une meilleure précision pour la prédiction du genre musical d'une chanson.\n",
        "L'oganisation de cette partie se découpe comme suit:\n",
        "##    Traitement des labels:\n",
        "Cette partie a pour simple objectif de récupérer l'ensemble des différents labels (genres musicaux) et de les encoder en vecteur one-hot afin que les algorithmes de classification puisse les traiter plus simplement.\n",
        "\n",
        "##    Récupération des différentes features pour chaque type de données:\n",
        "Pour les données audio, des algorithmes tels que MFCC et deep features sont utilisés pour extraire les caractéristiques du son. Pour les données d'image, les algorithmes tels que l'histogramme de couleur et HOG seront sélectionnés de part leur plus grande performance (qui a été évalué précedemment dans la partie unimodale) pour extraire les caractéristiques de l'image. Enfin, concernant les données textuelles, un algorithmes de BoW (Bag of Words) sera utilisé pour représenter les données textuelles sous forme numérique.\n",
        "\n",
        "##    Réalisation de la fusion précoce et tardive:\n",
        "La fusion précoce implique de combiner les caractéristiques des différentes modalités avant l'entraînement de l'algorithme de classification.\n",
        "\n",
        "Concernant la fusion tardive, une fois que les différentes caractéristiques ont été extraites pour chaque type de données, il est possible de les utiliser pour entraîner des algorithmes de classification préalablement sélectionnés pour chaque modalité. Ensuite, la fusion tardive peut être réalisée en combinant les résultats des algorithmes de chaque modalité pour obtenir une prédiction finale. La fusion précoce implique de combiner les caractéristiques des différentes modalités avant l'entraînement de l'algorithme de classification."
      ],
      "metadata": {
        "id": "TbedcNCofxak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traitement des labels"
      ],
      "metadata": {
        "id": "7SYvfQkToNaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(mapping.genre.unique())\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFbvRjaypusG",
        "outputId": "e46f3f3e-11c4-475e-ca44-21fd13afdebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Rock', 'Rap', 'Jazz', 'Reggae', 'World', 'Metal', 'Pop', 'Country', 'Electronic', 'Latin', 'RnB', 'Blues', 'Folk', 'Punk', 'New Age']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHf6ms9Bfm6V"
      },
      "source": [
        "def onehotcode(k, n):\n",
        "    code = n*[0]\n",
        "    code[k] = 1\n",
        "    return code"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7RM2l5jl2_y"
      },
      "source": [
        "def load_labels(rows):\n",
        "    y = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    for index, row in rows.iterrows():\n",
        "        print(f'\\rRow {index+1}/{n}', end='')\n",
        "        y.append(onehotcode(labels.index(row['genre']), len(labels)))\n",
        "    print()\n",
        "    return np.vstack(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y4faQLjmbxN"
      },
      "source": [
        "y_train = mapping[mapping.set == 'train'].genre\n",
        "y_val = mapping[mapping.set == 'val'].genre\n",
        "y_test = mapping[mapping.set == 'test'].genre"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('y_train:',len(y_train),'y_val:',len(y_val),'y_test:',len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNsG7WDYqOXK",
        "outputId": "69ae781e-a5a5-49e7-95cb-1652c43c9052"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y_train: 21383 y_val: 4680 y_test: 4649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnNV1st43_pw"
      },
      "source": [
        "On utilise le module sci-kit learn pour transformer nos listes de classes en one-hot-code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTMP6cmRxbEO"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "encoder = LabelBinarizer()\n",
        "y_train_bin = encoder.fit_transform(y_train)\n",
        "y_val_bin = encoder.transform(y_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traitement des données"
      ],
      "metadata": {
        "id": "TislIgO7qsyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traitement des audios"
      ],
      "metadata": {
        "id": "4eryNtBoqk3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def load_audio_deep_features(rows, filename):\n",
        "    X = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    npyfile = np.load('msdi/deep_features/' + filename)\n",
        "    for index, row in rows.iterrows():\n",
        "        x = npyfile[row['deep_features']]\n",
        "        X.append(x)\n",
        "    return np.vstack(X)"
      ],
      "metadata": {
        "id": "jNok6ING8JaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR4b3VPZSu3M"
      },
      "source": [
        "def load_audio_MFCC_features(rows):\n",
        "    X = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    for index, row in rows.iterrows():\n",
        "        npzfile = np.load('msdi/' + row['mfcc'])\n",
        "        x = npzfile[row['msd_track_id']]\n",
        "        X.append(aggregate(x))\n",
        "    return np.vstack(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9RaheRg7zE"
      },
      "source": [
        "from librosa.feature import delta\n",
        "\n",
        "def aggregate(x, delta=0):\n",
        "    feats = [x]\n",
        "    for i in range(delta):\n",
        "        feats.append(delta(x, order=i+1, axis=0))\n",
        "    return np.hstack(feats).mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQtX-IO_EmFl"
      },
      "source": [
        "X_audio_deep_train = load_audio_deep_features(mapping[mapping.set == 'train'], 'X_train_audio_MSD-I.npy')\n",
        "X_audio_deep_val = load_audio_deep_features(mapping[mapping.set == 'val'], 'X_val_audio_MSD-I.npy')\n",
        "X_audio_deep_test = load_audio_deep_features(mapping[mapping.set == 'test'], 'X_test_audio_MSD-I.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSwRZ8uoVUpN"
      },
      "source": [
        "X_audio_MFCC_train = load_audio_MFCC_features(mapping[mapping.set == 'train'])\n",
        "X_audio_MFCC_val = load_audio_MFCC_features(mapping[mapping.set == 'val'])\n",
        "X_audio_MFCC_test = load_audio_MFCC_features(mapping[mapping.set == 'test'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traitement des images"
      ],
      "metadata": {
        "id": "zUH4fC5_53Nb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.feature import hog\n",
        "from skimage import exposure"
      ],
      "metadata": {
        "id": "I9pSeMm3x-do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "P = Q = 3 # taille des blocs (images par blocs)\n",
        "B = 8 # nombre de bins (directions de gradients considérées)"
      ],
      "metadata": {
        "id": "PNZ5Xi7ol0lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nkAMVRfCgZ_"
      },
      "outputs": [],
      "source": [
        "# Fonction nous permettant de récupérer les histogrammes par bloc pour chaque image :\n",
        "def extract_hist(image, P=P, Q=Q, B=B):\n",
        "    M = (image.shape[0]//P)+1\n",
        "    N = (image.shape[1]//Q)+1\n",
        "    tiles = [image[x:x+M,y:y+N] for x in range(0,image.shape[0],M) for y in range(0,image.shape[1],N)]\n",
        "    return np.concatenate([np.histogram(tile[:,:,c].reshape(-1), bins=B, range=(0, 255))[0] for c in range(image.shape[2]) for tile in tiles])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnrSGGo6CiLx"
      },
      "outputs": [],
      "source": [
        "# Fonction nous permettant de récupérer le HOG_vector pour chaque image :\n",
        "def extract_hog(image, P=P, Q=Q, B=B):\n",
        "  return hog(image, orientations=B, pixels_per_cell=(image.shape[0]//P, image.shape[1]//Q), cells_per_block=(1, 1), multichannel=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_features(rows):\n",
        "    hist = []\n",
        "    hogs = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    for index, row in rows.iterrows():\n",
        "        print(f'\\rRow {index+1}/{n}', end='')\n",
        "        img = plt.imread('msdi/' + row['img'])\n",
        "        hist.append(extract_hist(img))\n",
        "        hogs.append(extract_hog(img))\n",
        "               \n",
        "    print()\n",
        "    return np.vstack(hist), np.vstack(hogs)"
      ],
      "metadata": {
        "id": "Wrl4_kVdmgua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image_hist_train, X_image_hog_train = load_image_features(mapping[mapping.set == 'train'])\n",
        "X_image_hist_val, X_image_hog_val = load_image_features(mapping[mapping.set == 'val'])\n",
        "X_image_hist_test, X_image_hog_test = load_image_features(mapping[mapping.set == 'test'])"
      ],
      "metadata": {
        "id": "WLKsBnXKnoEX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c072bb60-1572-49bc-bb28-c9998c73962e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 21383/21383\n",
            "Row 4680/4680\n",
            "Row 4649/4649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0N8mDwgzXSmy"
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "\n",
        "# fonction qui renvoie l'image des couleurs moyennes par bloc pour chaque image\n",
        "def extract_mean(image, P=P, Q=Q):\n",
        "    return resize(image, output_shape=(P, Q), anti_aliasing=True).flatten()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image_features_mean(rows):\n",
        "    means = []\n",
        "    hogs = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    for index, row in rows.iterrows():\n",
        "        print(f'\\rRow {index+1}/{n}', end='')\n",
        "        img = plt.imread('msdi/' + row['img'])\n",
        "        means.append(extract_mean(img))\n",
        "        hogs.append(extract_hog(img))\n",
        "               \n",
        "    print()\n",
        "    return np.vstack(means), np.vstack(hogs)"
      ],
      "metadata": {
        "id": "2ja1Kw2AgbMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_image_mean_train, X_image_hog_train = load_image_features_mean(mapping[mapping.set == 'train'])\n",
        "X_image_mean_val, X_image_hog_val = load_image_features_mean(mapping[mapping.set == 'val'])\n",
        "X_image_mean_test, X_image_hog_test = load_image_features_mean(mapping[mapping.set == 'test'])"
      ],
      "metadata": {
        "id": "-BYiGhg7bnzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ece66c-a756-4fcc-b9a1-225fce35136e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 21383/21383\n",
            "Row 4680/4680\n",
            "Row 4649/4649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traitement des textes"
      ],
      "metadata": {
        "id": "XnOBg1P4qo17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://pageperso.lis-lab.fr/benoit.favre/files/msx_lyrics_genre.txt.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssdpKpjsqrdS",
        "outputId": "2810fca2-57f8-4cc0-d124-6c8ad964cb7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-06 20:12:24--  https://pageperso.lis-lab.fr/benoit.favre/files/msx_lyrics_genre.txt.gz\n",
            "Resolving pageperso.lis-lab.fr (pageperso.lis-lab.fr)... 139.124.22.27\n",
            "Connecting to pageperso.lis-lab.fr (pageperso.lis-lab.fr)|139.124.22.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2715032 (2.6M) [application/x-gzip]\n",
            "Saving to: ‘msx_lyrics_genre.txt.gz’\n",
            "\n",
            "msx_lyrics_genre.tx 100%[===================>]   2.59M  3.56MB/s    in 0.7s    \n",
            "\n",
            "2023-02-06 20:12:26 (3.56 MB/s) - ‘msx_lyrics_genre.txt.gz’ saved [2715032/2715032]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gzip -d -f msx_lyrics_genre.txt.gz"
      ],
      "metadata": {
        "id": "9PoeyKE4rO9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head msx_lyrics_genre.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uNzY59brRdY",
        "outputId": "223e7a83-3c11-4056-f43d-fe8f9536eab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAAAHZ128E0799171 Rap 1:39 2:30 3:10 4:10 5:28 6:21 7:1 8:20 9:11 10:12 11:9 12:10 13:9 14:1 15:5 16:11 17:4 18:1 19:1 20:17 22:7 23:4 24:1 26:2 27:2 28:5 29:1 30:6 31:5 32:4 33:2 35:1 36:1 37:8 39:2 40:3 41:2 44:1 45:11 48:16 49:1 50:2 51:2 52:6 54:4 55:3 57:2 58:1 59:1 61:1 62:4 65:1 66:2 69:3 70:1 72:2 76:7 78:3 81:1 82:1 85:2 86:1 88:2 93:2 94:1 95:3 98:1 99:1 100:1 106:3 107:1 108:1 109:1 110:1 111:11 116:1 119:1 133:1 134:2 135:3 136:4 137:1 153:1 155:1 166:1 185:1 190:1 192:1 200:1 201:1 203:2 205:3 206:1 207:1 210:1 216:2 219:1 223:3 228:1 239:1 242:1 244:1 261:1 262:1 277:1 278:1 285:1 289:3 291:3 302:1 304:1 323:1 325:1 327:2 332:6 338:1 339:1 344:1 349:1 355:1 357:3 358:1 363:1 368:1 371:1 378:3 389:1 396:6 410:1 413:1 427:1 431:2 439:1 446:1 448:1 452:1 455:3 456:1 470:1 494:1 500:1 503:1 520:1 525:1 537:1 539:1 546:1 548:1 555:4 578:1 597:1 608:1 615:2 618:3 631:1 646:1 658:2 659:1 663:1 693:1 707:3 712:1 739:1 752:3 811:1 836:2 867:1 868:3 886:2 901:1 918:1 924:1 948:1 1021:1 1037:1 1057:1 1064:2 1067:1 1097:1 1171:1 1182:1 1192:3 1195:2 1230:1 1260:3 1321:1 1330:1 1337:7 1354:2 1381:2 1400:1 1432:1 1508:1 1611:1 1640:1 1670:6 1683:1 1688:1 1745:1 1749:3 1813:1 1885:1 1915:4 1938:1 2016:1 2125:1 2149:1 2189:2 2246:1 2282:1 2337:2 2411:1 2468:1 2614:13 2648:1 2854:1 2917:1 2933:1 3195:1 3612:1 3656:1 3831:1 4036:1 4135:1\n",
            "TRAACER128F4290F96 Metal 1:4 2:11 3:19 4:4 5:4 6:2 7:3 8:7 9:2 10:4 11:2 13:3 14:5 16:1 18:6 19:4 20:2 21:5 22:3 23:1 25:3 26:3 28:5 29:1 30:2 31:1 34:2 36:2 40:2 41:1 43:2 44:1 45:1 49:2 51:3 55:1 58:3 61:1 63:2 66:1 67:3 73:3 76:1 78:3 81:1 84:2 85:1 88:1 89:2 91:2 93:2 95:1 96:1 98:6 101:3 120:1 123:1 127:1 130:2 131:1 137:1 142:1 146:3 150:1 153:1 154:1 160:2 161:1 163:2 167:1 182:1 186:1 187:2 194:1 197:2 204:4 207:1 213:2 217:1 219:1 224:1 238:1 247:2 259:1 260:2 267:1 276:1 278:1 281:1 282:1 312:1 337:2 338:2 353:1 373:1 374:1 384:1 398:3 431:1 453:1 454:1 484:1 512:1 518:1 537:1 544:1 591:1 615:1 631:1 637:2 654:1 678:1 912:1 929:3 1500:1 1860:3 2175:1 2536:2 3138:3 3331:1 3662:1 4865:1\n",
            "TRAADYB128F92D7E73 Jazz 1:23 2:18 3:31 5:4 7:3 8:2 9:6 11:6 21:3 23:3 25:3 27:3 28:2 29:3 30:2 32:2 34:2 40:6 44:5 48:3 55:10 61:2 62:5 69:5 79:5 81:3 83:3 94:19 111:6 113:3 123:6 135:2 146:2 187:3 214:2 232:2 240:3 294:5 350:3 376:2 420:4 554:2 677:2 914:2 1059:3 1409:2\n",
            "TRAAEJV128F423CF04 Pop 1:11 3:19 6:3 7:1 10:1 12:7 13:1 17:1 22:1 23:1 25:2 26:1 30:3 33:9 36:3 43:3 56:7 61:1 68:1 82:3 84:2 85:1 88:1 89:1 103:1 133:1 186:1 211:1 247:1 264:3 360:1 419:1 499:8 617:3 680:1 2766:1\n",
            "TRAAERZ128F1496921 Reggae 1:13 2:12 3:9 4:3 5:13 6:3 8:1 9:1 11:3 12:2 14:1 15:2 16:4 17:6 18:4 21:3 22:11 23:2 24:3 25:2 26:5 27:2 28:1 30:10 31:4 32:2 33:3 36:2 37:3 39:9 40:3 41:1 46:5 48:1 56:1 64:1 66:1 68:3 73:1 76:4 81:8 83:1 85:2 86:2 91:1 94:1 95:1 109:3 110:1 113:1 124:6 129:1 131:2 134:2 153:1 172:2 178:4 192:2 197:1 199:2 206:6 227:1 233:1 255:2 262:1 266:2 267:1 277:1 280:1 287:1 323:3 329:2 354:3 371:3 375:2 393:1 399:1 439:1 468:2 605:1 762:2 825:3 930:3 1031:2 3513:2\n",
            "TRAAHSY128F147BB5C Rock 1:5 2:5 3:10 4:4 5:3 6:4 7:4 8:3 9:3 10:1 11:2 12:5 14:1 16:1 17:2 21:1 22:1 24:1 25:1 26:2 27:2 28:3 29:2 30:1 33:1 34:1 36:2 39:1 43:2 51:2 55:1 56:2 58:1 60:1 62:2 63:1 68:2 81:1 84:1 94:1 108:1 116:1 120:1 126:1 131:1 136:1 139:1 143:1 144:1 145:1 152:1 162:1 166:1 178:2 182:1 201:2 244:1 249:1 252:1 254:1 259:1 277:1 280:1 284:1 307:1 308:2 367:1 373:1 374:1 376:2 377:1 407:1 414:1 420:1 423:1 699:1 742:1 855:1 906:1 1591:1 2102:1 2187:1 3056:1\n",
            "TRAAIAE128F42AC53D Country 1:9 3:4 4:4 6:3 7:1 8:2 9:4 10:5 11:5 12:1 13:5 15:2 19:2 21:3 26:3 27:2 28:3 31:1 34:3 39:4 45:2 46:1 49:2 62:2 64:1 66:3 70:4 75:3 81:1 99:1 107:5 119:3 121:2 124:2 127:1 171:1 203:4 216:2 245:1 270:1 308:1 355:1 375:1 398:1 439:1 468:2 510:1 546:1 581:1 844:3 955:1 961:1 1281:1 1662:2 2453:2\n",
            "TRAAJJW12903CBDDCB Reggae 10:14 22:5 28:1 97:9 102:4 122:2 158:7 189:13 212:7 218:21 226:1 365:2 385:6 400:5 410:1 442:5 463:3 480:6 483:3 498:4 541:3 559:14 579:17 653:2 734:5 785:2 807:6 919:3 920:5 958:5 1025:3 1039:2 1060:1 1082:2 1088:2 1164:1 1240:6 1258:1 1480:4 1509:4 1530:4 1538:1 1558:1 1583:2 1596:2 1678:1 2195:1 2350:4 2369:5 2443:1 2869:6 2991:18 3293:9 3362:1 3834:1 3884:2 4166:3\n",
            "TRAALDI128EF35F6DD Rock 1:9 2:3 3:8 4:7 8:3 9:1 13:1 14:1 17:1 18:2 21:1 22:1 26:3 27:1 28:1 29:2 30:3 32:1 33:1 37:2 40:7 43:1 44:3 58:1 61:2 66:2 68:2 69:1 71:1 74:2 83:5 84:2 86:3 88:1 92:4 105:1 111:1 119:1 132:1 139:1 147:1 166:1 172:1 192:2 202:2 211:1 223:2 225:1 268:2 271:1 284:1 294:1 340:2 367:1 372:2 427:1 429:1 468:1 608:1 789:2 898:1 1351:1 1460:1 1745:2 1803:3 1945:2\n",
            "TRAALWY128F423EE73 Rock 1:12 2:7 3:9 4:9 5:2 6:2 7:7 8:1 9:1 11:5 13:1 14:1 16:1 18:1 20:8 21:1 23:1 25:1 26:1 32:7 33:11 37:1 49:1 51:3 52:3 53:1 61:1 62:1 64:2 67:1 68:1 72:1 79:1 80:1 86:5 88:1 92:2 98:1 99:1 100:1 101:1 107:1 109:1 131:1 139:3 143:2 145:1 161:1 167:1 178:1 188:1 215:1 227:1 234:1 237:3 238:7 340:1 358:1 392:1 417:1 452:3 500:1 512:1 622:2 723:2 921:1 1127:1 1147:1 1298:1 1415:1 1420:1 1442:1 1757:1 2056:3 2479:1 2558:1 2963:1 3668:1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOS9oElytlwc"
      },
      "source": [
        "bag_of_words = {}\n",
        "file = open('msx_lyrics_genre.txt')\n",
        "for line in file.readlines():\n",
        "    id, _, *words = line.split(' ')\n",
        "    bag_of_words[id] = dict([map(int, word.split(':')) for word in words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = int(max([word_id for words in bag_of_words.values() for word_id in words.keys()]))\n",
        "max_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE75CvO7rS6E",
        "outputId": "fa501b04-ff8e-49ae-abc2-a6b3257cb222"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gTpQ6wh5UXp"
      },
      "source": [
        "def load_text_features(rows):\n",
        "    X = []\n",
        "    n = len(rows)\n",
        "    rows.reset_index(drop=True, inplace=True)\n",
        "    for index, row in rows.iterrows():\n",
        "        print(f'\\rRow {index+1}/{n}', end='')\n",
        "        x = np.zeros(max_length)\n",
        "        if row['msd_track_id'] in bag_of_words:\n",
        "            bag_of_word = bag_of_words[row['msd_track_id']]\n",
        "            indices = np.array(list(bag_of_word.keys())) - 1\n",
        "            values = list(bag_of_word.values())\n",
        "            x[indices] = values\n",
        "        X.append(x)\n",
        "    print()\n",
        "    return np.vstack(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_text_train = load_text_features(mapping[mapping.set == 'train'])\n",
        "X_text_val = load_text_features(mapping[mapping.set == 'val'])\n",
        "X_text_test = load_text_features(mapping[mapping.set == 'test'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95keFMqct9db",
        "outputId": "e8e29444-3db0-4878-ec52-7d566957ad43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Row 21383/21383\n",
            "Row 4680/4680\n",
            "Row 4649/4649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [X_audio_deep_train, X_audio_MFCC_train, X_image_hist_train, X_image_hog_train, X_text_train]\n",
        "X_test = [X_audio_deep_test, X_audio_MFCC_test, X_image_hist_test, X_image_hog_test, X_text_test]\n",
        "X_val = [X_audio_deep_val, X_audio_MFCC_val, X_image_hist_val, X_image_hog_val, X_text_val]"
      ],
      "metadata": {
        "id": "EkvfBvH6x1QT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy8nrYOZ2jrI"
      },
      "source": [
        "X_train = np.hstack(X_train)\n",
        "X_val = np.hstack(X_val)\n",
        "X_test = np.hstack(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rdv7-InfT43",
        "outputId": "8c5372e1-7417-4618-d70b-dbc11c087346"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(21383, 7348)\n",
            "(21383, 7348)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Early fusion"
      ],
      "metadata": {
        "id": "q_PR2MAADos2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CP53YGUIvEE2"
      },
      "outputs": [],
      "source": [
        "X_train_list = [X_audio_deep_train, X_audio_MFCC_train, X_image_hist_train, X_image_hog_train, X_text_train]\n",
        "X_test_list = [X_audio_deep_test, X_audio_MFCC_test, X_image_hist_test, X_image_hog_test, X_text_test]\n",
        "X_val_list = [X_audio_deep_val, X_audio_MFCC_val, X_image_hist_val, X_image_hog_val, X_text_val]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oj3sYftZRuT_"
      },
      "outputs": [],
      "source": [
        "X_train = np.hstack(X_train_list)\n",
        "X_val = np.hstack(X_val_list)\n",
        "X_test = np.hstack(X_test_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrEGpTYQXRd0"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.losses import categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKPZfi4UlIAO"
      },
      "outputs": [],
      "source": [
        "# Etablissement du modèle\n",
        "model = Sequential()\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dense(15, activation=\"softmax\"))\n",
        "model.compile(loss=categorical_crossentropy, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDol2JeDiwIc",
        "outputId": "17a9a53c-b009-4bf4-f5f8-412b13f8ce0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "669/669 [==============================] - 36s 51ms/step - loss: 12.4405 - accuracy: 0.1585 - val_loss: 2.5431 - val_accuracy: 0.1543\n",
            "Epoch 2/5\n",
            "669/669 [==============================] - 32s 47ms/step - loss: 2.5448 - accuracy: 0.1761 - val_loss: 2.6453 - val_accuracy: 0.1526\n",
            "Epoch 3/5\n",
            "669/669 [==============================] - 32s 47ms/step - loss: 2.4878 - accuracy: 0.1738 - val_loss: 2.5327 - val_accuracy: 0.1524\n",
            "Epoch 4/5\n",
            "669/669 [==============================] - 33s 49ms/step - loss: 2.4746 - accuracy: 0.1740 - val_loss: 2.5520 - val_accuracy: 0.1509\n",
            "Epoch 5/5\n",
            "669/669 [==============================] - 34s 50ms/step - loss: 2.4514 - accuracy: 0.1712 - val_loss: 2.5356 - val_accuracy: 0.1517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2da01915b0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Entrainement du modèle\n",
        "model.fit(X_train, y_train_bin, epochs=5, validation_data=(X_val, y_val_bin))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle ne semble pas efficace avec ces features. Il semble que modèle classfiie tous les sons dans la catégorie prédominante du dataset. Un travail a été effectué pour enlever les déséquilibres de distribution des classes du dataset mais aucun résultat n'a été perçu. Essayons avec les features des images aggrégées par moyennes, qui sont des features moins complexes à interpréter. "
      ],
      "metadata": {
        "id": "TfWYiTtwf3I1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_list = [X_audio_deep_train, X_audio_MFCC_train, X_image_mean_train, X_image_hog_train, X_text_train]\n",
        "X_test_list = [X_audio_deep_test, X_audio_MFCC_test, X_image_hist_test, X_image_hog_test, X_text_test]\n",
        "X_val_list = [X_audio_deep_val, X_audio_MFCC_val, X_image_hist_val, X_image_hog_val, X_text_val]"
      ],
      "metadata": {
        "id": "cmRSi_VAgBRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.hstack(X_train_list)\n",
        "X_val = np.hstack(X_val_list)\n",
        "X_test = np.hstack(X_test_list)"
      ],
      "metadata": {
        "id": "PEQ3e6r_gEEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b5fa289-57af-4369-9243-4aad1fe77c9e",
        "id": "Tc2kq1qSrmOT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "669/669 [==============================] - 27s 39ms/step - loss: 1.4358 - accuracy: 0.5401 - val_loss: 1.5074 - val_accuracy: 0.5203\n",
            "Epoch 2/5\n",
            "669/669 [==============================] - 26s 40ms/step - loss: 1.1862 - accuracy: 0.6187 - val_loss: 1.5358 - val_accuracy: 0.5267\n",
            "Epoch 3/5\n",
            "669/669 [==============================] - 29s 43ms/step - loss: 1.0703 - accuracy: 0.6613 - val_loss: 1.6823 - val_accuracy: 0.5417\n",
            "Epoch 4/5\n",
            "669/669 [==============================] - 26s 39ms/step - loss: 0.9633 - accuracy: 0.6964 - val_loss: 1.8826 - val_accuracy: 0.5226\n",
            "Epoch 5/5\n",
            "669/669 [==============================] - 26s 38ms/step - loss: 0.8633 - accuracy: 0.7267 - val_loss: 2.0495 - val_accuracy: 0.5244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0ef0d1ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# entrainement\n",
        "model.fit(X_train, y_train_bin, epochs=5, validation_data=(X_val, y_val_bin))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d1a684-e251-439a-95e0-82b815be8ed3",
        "id": "dbYKS07ZrmOV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146/146 [==============================] - 1s 9ms/step\n"
          ]
        }
      ],
      "source": [
        " # prédictions\n",
        "y_proba = model.predict(X_test) #one-hot-code encoded predictions\n",
        "y_pred = encoder.inverse_transform(y_proba) #convert back to class names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6588995f-c7f4-4da6-c14b-fb503b923fe3",
        "id": "MoGBULFJrmOV"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Blues       0.27      0.43      0.33       121\n",
            "     Country       0.59      0.36      0.45       316\n",
            "  Electronic       0.73      0.69      0.71       751\n",
            "        Folk       0.24      0.17      0.19       193\n",
            "        Jazz       0.53      0.57      0.55       433\n",
            "       Latin       0.47      0.44      0.46        86\n",
            "       Metal       0.63      0.84      0.72       282\n",
            "     New Age       0.18      0.23      0.20        31\n",
            "         Pop       0.55      0.44      0.49       573\n",
            "        Punk       0.23      0.26      0.25        84\n",
            "         Rap       0.74      0.78      0.76       360\n",
            "      Reggae       0.49      0.60      0.54       217\n",
            "         RnB       0.44      0.48      0.46       359\n",
            "        Rock       0.54      0.54      0.54       826\n",
            "       World       0.07      0.18      0.10        17\n",
            "\n",
            "    accuracy                           0.55      4649\n",
            "   macro avg       0.45      0.47      0.45      4649\n",
            "weighted avg       0.56      0.55      0.55      4649\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# évaluation \n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_pred, y_test, target_names=encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Le modèle semble fonctionner avec des résultats de bonnes qualités."
      ],
      "metadata": {
        "id": "qXFFR3ZsrwUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fusion tardive"
      ],
      "metadata": {
        "id": "oWBRa5p20fY6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkO1-fO60f2e"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "tSNlxRKr3eZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans un premier temps nous réalisons les algorithmes unimodaux des différentes features que nous combinerons dans un second temps afin de réaliser la fusion tardive."
      ],
      "metadata": {
        "id": "eIfzpf9huJIJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audios"
      ],
      "metadata": {
        "id": "mnJgUdmEAktZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MFCC"
      ],
      "metadata": {
        "id": "DdMX2x9HBXrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_mfcc = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=9, n_estimators=50))\n",
        "pipeline_mfcc.fit(np.concatenate((X_audio_MFCC_train, X_audio_MFCC_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n",
        "val_mfcc = np.mean(cross_val_score(pipeline_mfcc, np.concatenate((X_audio_MFCC_train, X_audio_MFCC_val), axis=0), np.concatenate((y_train, y_val), axis=0), cv=5))\n"
      ],
      "metadata": {
        "id": "-7-h9_coA2Bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4d5c43-a6dc-4da7-a77d-eece7c3963ca",
        "id": "asuRgSKyA2By"
      },
      "source": [
        "# accuracy en validation croisée\n",
        "\n",
        "print(val_mfcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4194833036659782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88ba8752-d455-456f-d169-6e67522506b5",
        "id": "vvuDZUGbA2B0"
      },
      "source": [
        "# accuracy en test\n",
        "acc_mfcc = pipeline_mfcc.score(X_audio_MFCC_test, y_test)\n",
        "print(acc_mfcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4177242417724242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa1cbade-6605-4b44-e6b1-97b5126e61df",
        "id": "dzRr0HUOA2B1"
      },
      "source": [
        "# aire sous la courbe ROC en test\n",
        "from sklearn.metrics import roc_auc_score\n",
        "y_proba_mfcc = pipeline_mfcc.predict_proba(X_audio_MFCC_test)\n",
        "roc_mfcc = roc_auc_score(y_test, y_proba_mfcc, multi_class='ovr')\n",
        "print(roc_mfcc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8468963827749605\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep features"
      ],
      "metadata": {
        "id": "3gv_W2fOBfMR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_df = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=9, n_estimators=50))\n",
        "pipeline_df.fit(np.concatenate((X_audio_deep_train, X_audio_deep_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n",
        "val_df = np.mean(cross_val_score(pipeline_df, np.concatenate((X_audio_deep_train, X_audio_deep_val), axis=0), np.concatenate((y_train, y_val), axis=0), cv=5))\n"
      ],
      "metadata": {
        "id": "7W2mCoV5BfMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594cd06f-299b-4085-bee8-281bdf38d010",
        "id": "TkWPuIOOBfMU"
      },
      "source": [
        "# accuracy en validation croisée\n",
        "\n",
        "print(val_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5054279482237791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3628e0-f250-497d-b0c5-a3fe8a9bd763",
        "id": "NiE09F2VBfMX"
      },
      "source": [
        "# accuracy en test\n",
        "acc_df = pipeline_df.score(X_audio_deep_test, y_test)\n",
        "print(acc_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.49343944934394496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9812a0ff-bad5-462f-b2db-ede363953842",
        "id": "41rIRZ8QBfMZ"
      },
      "source": [
        "# aire sous la courbe ROC en test\n",
        "from sklearn.metrics import roc_auc_score\n",
        "y_proba_df = pipeline_df.predict_proba(X_audio_deep_test)\n",
        "roc_df = roc_auc_score(y_test, y_proba_df, multi_class='ovr')\n",
        "print(roc_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.860756673020489\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Images"
      ],
      "metadata": {
        "id": "T2-dc5X_8RKT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HIST"
      ],
      "metadata": {
        "id": "qN69mYUz0f2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_hist = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=9, n_estimators=50))\n",
        "pipeline_hist.fit(np.concatenate((X_image_hist_train, X_image_hist_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n",
        "val_hist = np.mean(cross_val_score(pipeline_hist, np.concatenate((X_image_hist_train, X_image_hist_val), axis=0), np.concatenate((y_train, y_val), axis=0), cv=5))\n"
      ],
      "metadata": {
        "id": "L6ywn67q4oFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23de0ef-d097-4521-fe23-8b7472364ba6",
        "id": "0eLe33BX0f2k"
      },
      "source": [
        "# accuracy en validation croisée\n",
        "\n",
        "print(val_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.3817628430252664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05cd5a43-13ee-454c-8ea7-938e9efe22af",
        "id": "7kZk-_NK0f2l"
      },
      "source": [
        "# accuracy en test\n",
        "acc_hist = pipeline_hist.score(X_image_hist_test, y_test)\n",
        "print(acc_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.20456012045601205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f70a93f-c81b-4756-d0c5-16032376433f",
        "id": "d4HCKIiM0f2m"
      },
      "source": [
        "# aire sous la courbe ROC en test\n",
        "from sklearn.metrics import roc_auc_score\n",
        "y_proba_hist = pipeline_hist.predict_proba(X_image_hist_test)\n",
        "roc_hist = roc_auc_score(y_test, y_proba_hist, multi_class='ovr')\n",
        "print(roc_hist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6116941269567001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HOG"
      ],
      "metadata": {
        "id": "lsKwVxH2za1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_hog = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=9, n_estimators=50))\n",
        "pipeline_hog.fit(np.concatenate((X_image_hog_train, X_image_hog_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzsbQcCk6Ih7",
        "outputId": "f8e96d9f-4243-4be8-8692-eba5f5679d8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(max_depth=9, n_estimators=50))])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjstoertki-b"
      },
      "source": [
        "val_hog = np.mean(cross_val_score(pipeline_hog, np.concatenate((X_image_hog_train, X_image_hog_val), axis=0), np.concatenate((y_train, y_val), axis=0), cv=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uV_wQbhNmQFA",
        "outputId": "68c39493-c7f8-4c64-c18b-c3caf29c5272"
      },
      "source": [
        "print(val_hog)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2978524819658746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s98tQWREki-b",
        "outputId": "47c219d3-6cf3-497e-c738-4e7fce212a33"
      },
      "source": [
        "# accuracy en test\n",
        "acc_hog = pipeline_hog.score(X_image_hog_test, y_test)\n",
        "print(acc_hog)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.19359001935900194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB7ahq3Mki-c",
        "outputId": "dca7159a-4313-4214-e70c-627b031cc361"
      },
      "source": [
        "#ROC en test\n",
        "from sklearn.metrics import roc_auc_score\n",
        "y_proba_hog = pipeline_hog.predict_proba(X_image_hog_test)\n",
        "roc_hog = roc_auc_score(y_test, y_proba_hog, multi_class='ovr')\n",
        "print(roc_hog)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6012921734366118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Textes"
      ],
      "metadata": {
        "id": "pld9ikp1qFBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bag of Words"
      ],
      "metadata": {
        "id": "XSPR_FtT7JCP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_bow = make_pipeline(StandardScaler(), RandomForestClassifier(max_depth=9, n_estimators=50))\n",
        "pipeline_bow.fit(np.concatenate((X_text_train, X_text_val), axis=0), np.concatenate((y_train, y_val), axis=0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86d567fd-55b0-4ee7-ec73-058a202e26f9",
        "id": "Ns7u8Swz7OJ_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
              "                ('randomforestclassifier',\n",
              "                 RandomForestClassifier(max_depth=9, n_estimators=50))])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Pr9ioOf7OKB"
      },
      "source": [
        "val_bow = np.mean(cross_val_score(pipeline_bow, np.concatenate((X_text_train, X_text_val), axis=0), np.concatenate((y_train, y_val), axis=0), cv=5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3034ef-342a-49f6-a448-0564b2121349",
        "id": "ZesjwL2v7OKC"
      },
      "source": [
        "print(val_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2907180731682218\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545f3ce1-3592-4ec3-9152-42b6383ca91b",
        "id": "60fxMTcW7OKD"
      },
      "source": [
        "# accuracy en test\n",
        "acc_bow = pipeline_bow.score(X_text_test, y_test)\n",
        "print(acc_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.2903850290385029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92ff7497-7130-492a-a42d-d8138c752bd6",
        "id": "VWqA-cIv7OKE"
      },
      "source": [
        "#ROC en test\n",
        "y_proba_bow = pipeline_bow.predict_proba(X_text_test)\n",
        "roc_bow = roc_auc_score(y_test, y_proba_bow, multi_class='ovr')\n",
        "print(roc_bow)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.695429584432678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusion tardive à votes non pondérés"
      ],
      "metadata": {
        "id": "41sxBGfOCF7E"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykP1bZtpstNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c722e709-f7fa-4367-9dd0-6427aa2307b5"
      },
      "source": [
        "# liste des prédictions des estimateurs 1 à 1\n",
        "predictions = np.transpose(np.array([pipeline_mfcc.predict(X_audio_MFCC_test), pipeline_df.predict(X_audio_deep_test), pipeline_hist.predict(X_image_hist_test), pipeline_hog.predict(X_image_hog_test), pipeline_bow.predict(X_text_test)]))\n",
        "print(np.shape(predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4649, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Qz9mO3qkNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4be1fa4b-bf44-4dd1-a2ca-e0234ac6c20e"
      },
      "source": [
        "# prediction du vote\n",
        "dx, dy = np.shape(predictions)[0], np.shape(predictions)[1]\n",
        "occurences = []\n",
        "y_pred_vote_nonpond = []\n",
        "\n",
        "for i in range(dx):\n",
        "  occurences = [predictions[i, :].tolist().count(predictions[i, j]) for j in range(dy)]\n",
        "  k = np.argmax(occurences) # dans le cas où il y a autant de votes majoritaires pour plusieurs classes, c'est la 1ère de ces classes qui est sélectionnée\n",
        "  y_pred_vote_nonpond.append(predictions[i, k])\n",
        " \n",
        "# accuracy en test\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_vote_nonpond = accuracy_score(y_test, y_pred_vote_nonpond)\n",
        "print('accuracy du vote à la majorité sans pondération en test :', acc_vote_nonpond)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy du vote à la majorité sans pondération en test : 0.4099806409980641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQpzJDkfqydr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b52e10-b38f-4610-a3eb-d3bba6c7a4a0"
      },
      "source": [
        "# Probabilités de chaque classe\n",
        "y_probas = [y_proba_mfcc, y_proba_df, y_proba_hist, y_proba_hog, y_proba_bow]\n",
        "print(np.shape(y_probas))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 4649, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction probas classes\n",
        "y_proba_uni = np.mean(y_probas, axis=0)\n",
        "print(np.shape(y_proba_uni))\n",
        " "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFVT-vvurHqm",
        "outputId": "0337695f-04d4-4d79-8623-6394acb93a48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4649, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_nonpond = roc_auc_score(y_test, y_proba_uni, multi_class='ovr')\n",
        "print(roc_nonpond)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqDhQIN1qVeP",
        "outputId": "a2f1503e-749a-4cbf-e5cb-50a223a6a3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9031383074912048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fusion tardive à votes pondérés"
      ],
      "metadata": {
        "id": "h8qjNLd_Czej"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVfJhkeZsMqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b113b54-693f-4058-a401-32b2646b0483"
      },
      "source": [
        "# prediction classe\n",
        "y_pred_uni = pipeline_bow.classes_[np.argmax(y_proba_uni, axis=1)]\n",
        "print(np.shape(y_pred_uni))\n",
        " \n",
        "# accuracy \n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_uni = accuracy_score(y_test, y_pred_uni)\n",
        "print(acc_uni)\n",
        " \n",
        "# roc score \n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_uni = roc_auc_score(y_test, y_proba_uni, multi_class='ovr')\n",
        "print(roc_uni)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4649, 15)\n",
            "(4649,)\n",
            "0.46612174661217465\n",
            "0.9031383074912048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CkHD2w_VmQmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e6fa97d-76c1-48d8-857d-5decf14e15bd"
      },
      "source": [
        "# pondération donnée par l'accuracy obtenue en validation croisée\n",
        "pond = [val_mfcc, val_df, val_hist, val_hog, val_bow]\n",
        " \n",
        "# prediction probas classes\n",
        "y_proba_pond = np.average(y_probas, axis=0, weights=pond)\n",
        " \n",
        "# prediction classe\n",
        "y_pred_pond = pipeline_bow.classes_[np.argmax(y_proba_pond, axis=1)]\n",
        " \n",
        "# accuracy en test\n",
        "from sklearn.metrics import accuracy_score\n",
        "acc_vote_pond = accuracy_score(y_test, y_pred_pond)\n",
        "print('accuracy du vote à la majorité avec pondération en test :', acc_vote_pond)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy du vote à la majorité avec pondération en test : 0.48375994837599484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# roc score en test\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_pond = roc_auc_score(y_test, y_proba_pond, multi_class='ovr')\n",
        "print('score ROC en test :', roc_pond)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQhrVSqJDfi3",
        "outputId": "f5075ee0-a877-479e-d84f-5f31ce0b4911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score ROC en test : 0.9026313415384922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En utilisant une pondération, les algorithmes ayant une meilleure performance en validation croisée vont avoir plus de poids lors de la prise de décision finale pour faire des prédictions sur les données de test. Cela peut aider à éviter l'overfitting sur les données d'entraînement en permettant à plusieurs algorithmes de contribuer à la prédiction finale. De plus, cela peut aider à améliorer la précision de la prédiction en utilisant les forces de différents algorithmes pour compléter les faiblesses de chacun. Cela expliquerait pourquoi la fusion pondérée obtient une meilleure précision que la fusion sans pondération.\n"
      ],
      "metadata": {
        "id": "tc1hXJW2wc9k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "puQl520zsP3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Type | Features | Accuracy | ROC |\n",
        "|------|----------|----------|----------|\n",
        "| Unimodal | Son (MFCC)| 41,7% | 84,6 |\n",
        "| Unimodal | Son (Deep features)| 49% | 86% |\n",
        "| Unimodal | Image (histogramme)| 20,5% | 61,1% |\n",
        "| Unimodal | Image (HOG) | 19,4% | 60,1% |\n",
        "| Unimodal | Texte (BoW) | 29% | 69,5% |\n",
        "| Multimodal | Early-fusion | 0.45% | - |\n",
        "| Multimodal | Late-fusion à votes non pondérés | 41% | 90,3% |\n",
        "| Multimodal | Late-fusion à votes pondérés| 48,4% | 90,3% |\n",
        "\n"
      ],
      "metadata": {
        "id": "l7KwDgmBiYLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En conclusion, ce projet a exploré différents algorithmes multimodaux et unimodaux pour prédire le genre d'une musique à partir d'une image de couverture d'album, d'un extrait audio et de données textuelles. Les résultats montrent que les algorithmes de traitement du son sont les plus performants en termes de précision de classification avec un score de 49% pour les features de deep learning du son. Les algorithmes de traitement d'image ont eu des performances inférieures avec des scores de 20,5% pour l'histogramme de couleur et 19,4% pour HOG. Le traitement du texte a également donné des résultats inférieurs avec une précision de 29% pour l'utilisation de bag-of-words.\n",
        "\n",
        "Il y a plusieurs raisons qui pourraient expliquer pourquoi les données de son ont permis une plus grande précision que les données d'image et de texte pour la classification du genre musical.\n",
        "\n",
        "Tout d'abord, le son est un aspect clé de la musique et peut être utilisé pour capturer les caractéristiques distinctives du genre, telles que la fréquence, le tempo, les harmoniques et la timbre. Les algorithmes de traitement du son tels que les features MFCC et les features de deep learning peuvent extraire ces caractéristiques et les utiliser pour la classification.\n",
        "\n",
        "En comparaison, l'image de la couverture de l'album peut être influencée par de nombreux facteurs tels que le design, la couleur et les textes, ce qui peut rendre plus difficile la prédiction du genre musical car le lien peut souvent être très indirect. De même, les données textuelles telles que les titres de chansons et les informations de l'artiste peuvent être influencées par de nombreux facteurs tels que les erreurs de saisie et la subjectivité des étiquetages, ce qui peut également rendre la prédiction du genre musical difficile.\n",
        "\n",
        "Enfin, il est important de noter que les algorithmes de traitement du son ont été améliorés grâce à des années de recherche et de développement, ce qui a permis d'optimiser leur performance pour la classification du genre musical.\n",
        "\n",
        "En résumé, la performance supérieure des données de son pour la classification du genre musical peut être attribuée à la capacité de ces algorithmes à capturer les caractéristiques sonores distinctives de la musique, ainsi qu'à l'amélioration continue de ces algorithmes.\n",
        "\n",
        "Les algorithmes de fusion tardive (late-fusion) ont également été testés avec des votes non pondérés et pondérés. Les résultats montrent que la fusion tardive pondérée a donné les meilleurs résultats avec une précision de 48,4% et une courbe ROC de 90,3%. Cependant, il est important de noter que les résultats de la fusion tardive ne sont que la somme des résultats des algorithmes unimodaux, il est donc nécessaire d'optimiser les algorithmes unimodaux pour améliorer les performances globales.\n",
        "\n",
        "En général, ce projet montre que la prédiction du genre musical peut être un défi complexe et nécessite une combinaison judicieuse de différentes features pour obtenir des résultats satisfaisants. Il est donc nécessaire de continuer à explorer et à améliorer les algorithmes multimodaux pour optimiser la prédiction du genre musical."
      ],
      "metadata": {
        "id": "wJcWN7ohsROf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "7SYvfQkToNaG",
        "oWBRa5p20fY6"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}